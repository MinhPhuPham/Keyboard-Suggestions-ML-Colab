{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Word List Post-Processing & Cleanup\n",
                "\n",
                "This notebook cleans up `valid_words.csv` by:\n",
                "- **Removing trailing apostrophes** (word' → removed)\n",
                "- **Filtering 2-letter lowercase words** (except 'a' and 'i')\n",
                "- **Detecting and fixing 500+ acronyms** (Ny → NY, Fbi → FBI, Covid → COVID)\n",
                "\n",
                "**Input:** `valid_words.csv` (word, count)\n",
                "\n",
                "**Output:** `cleaned_words.csv` (cleaned and properly formatted)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required libraries\n",
                "!pip install pandas"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Upload Your CSV File\n",
                "\n",
                "**Instructions:**\n",
                "1. Click the **Folder icon** on the left sidebar\n",
                "2. Click the **Upload** button\n",
                "3. Select `valid_words.csv` from your computer\n",
                "4. Wait for the upload to complete"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Import Libraries and Define Comprehensive Acronym List"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import re\n",
                "\n",
                "# COMPREHENSIVE ACRONYM LIST (500+ acronyms)\n",
                "# All acronyms that should be fully uppercase\n",
                "KNOWN_ACRONYMS = {\n",
                "    # === US STATES (50) ===\n",
                "    'al', 'ak', 'az', 'ar', 'ca', 'co', 'ct', 'de', 'fl', 'ga',\n",
                "    'hi', 'id', 'il', 'in', 'ia', 'ks', 'ky', 'la', 'me', 'md',\n",
                "    'ma', 'mi', 'mn', 'ms', 'mo', 'mt', 'ne', 'nv', 'nh', 'nj',\n",
                "    'nm', 'ny', 'nc', 'nd', 'oh', 'ok', 'or', 'pa', 'ri', 'sc',\n",
                "    'sd', 'tn', 'tx', 'ut', 'vt', 'va', 'wa', 'wv', 'wi', 'wy',\n",
                "    \n",
                "    # === MAJOR CITIES ===\n",
                "    'nyc', 'la', 'sf', 'dc', 'philly',\n",
                "    \n",
                "    # === COUNTRIES & REGIONS ===\n",
                "    'usa', 'uk', 'eu', 'uae', 'ussr', 'prc', 'drc', 'uae', 'gcc',\n",
                "    \n",
                "    # === GOVERNMENT & AGENCIES ===\n",
                "    'fbi', 'cia', 'nsa', 'dea', 'atf', 'dhs', 'tsa', 'ice', 'cbp',\n",
                "    'epa', 'fda', 'fcc', 'ftc', 'sec', 'irs', 'ssa', 'osha',\n",
                "    'dod', 'doj', 'hhs', 'hud', 'dot', 'doe', 'va', 'dhs',\n",
                "    'nasa', 'noaa', 'usda', 'usps', 'dmv', 'cdc', 'nih',\n",
                "    'fema', 'darpa', 'nist', 'usgs', 'nrc', 'nlrb',\n",
                "    \n",
                "    # === MILITARY ===\n",
                "    'usaf', 'usmc', 'usn', 'army', 'navy', 'nato', 'un', 'seals',\n",
                "    'raf', 'sas', 'kgb', 'mi5', 'mi6', 'mossad', 'cia', 'nsa',\n",
                "    \n",
                "    # === HEALTH & MEDICAL ===\n",
                "    'hiv', 'aids', 'covid', 'sars', 'mers', 'h1n1', 'ebola',\n",
                "    'dna', 'rna', 'mrna', 'cpr', 'icu', 'er', 'emt', 'ems',\n",
                "    'adhd', 'ptsd', 'ocd', 'bmi', 'cdc', 'who', 'nih',\n",
                "    'std', 'sti', 'hpv', 'tb', 'ms', 'als', 'md', 'rn', 'lpn',\n",
                "    \n",
                "    # === TECHNOLOGY - GENERAL ===\n",
                "    'it', 'ai', 'ml', 'nlp', 'ocr', 'iot', 'ar', 'vr', 'xr',\n",
                "    'api', 'sdk', 'ide', 'gui', 'cli', 'ui', 'ux', 'qa', 'qc',\n",
                "    'cpu', 'gpu', 'ram', 'rom', 'ssd', 'hdd', 'usb', 'hdmi',\n",
                "    'wifi', 'lan', 'wan', 'vpn', 'ip', 'tcp', 'udp', 'dns',\n",
                "    'dhcp', 'nat', 'ssh', 'ssl', 'tls', 'https', 'http', 'ftp',\n",
                "    'smtp', 'pop', 'imap', 'voip', 'sip', 'rtp', 'rtsp',\n",
                "    'cdn', 'ddos', 'dos', 'xss', 'csrf', 'sql', 'nosql',\n",
                "    'rest', 'soap', 'grpc', 'graphql', 'crud', 'mvc', 'mvvm',\n",
                "    'oop', 'fp', 'tdd', 'bdd', 'ci', 'cd', 'devops', 'sre',\n",
                "    \n",
                "    # === PROGRAMMING LANGUAGES & FRAMEWORKS ===\n",
                "    'html', 'css', 'xml', 'json', 'yaml', 'sql', 'php', 'asp',\n",
                "    'jsp', 'js', 'ts', 'jsx', 'tsx', 'vue', 'svelte',\n",
                "    'ios', 'macos', 'tvos', 'watchos', 'ipados',\n",
                "    'aws', 'gcp', 'azure', 'ibm', 'sap', 'erp', 'crm',\n",
                "    \n",
                "    # === FILE FORMATS & EXTENSIONS ===\n",
                "    'pdf', 'doc', 'docx', 'xls', 'xlsx', 'ppt', 'pptx',\n",
                "    'jpg', 'jpeg', 'png', 'gif', 'svg', 'bmp', 'tiff', 'webp',\n",
                "    'mp3', 'mp4', 'avi', 'mkv', 'mov', 'wmv', 'flv', 'webm',\n",
                "    'wav', 'flac', 'aac', 'ogg', 'm4a', 'wma',\n",
                "    'zip', 'rar', 'tar', 'gz', '7z', 'iso', 'dmg',\n",
                "    'exe', 'dll', 'bat', 'sh', 'app', 'apk', 'ipa',\n",
                "    'csv', 'tsv', 'txt', 'rtf', 'md', 'log',\n",
                "    \n",
                "    # === COMPANIES - TECH ===\n",
                "    'ibm', 'hp', 'dell', 'amd', 'intel', 'nvidia', 'asus',\n",
                "    'msi', 'ati', 'arm', 'tsmc', 'qualcomm',\n",
                "    'att', 'verizon', 'tmobile', 'sprint',\n",
                "    'sap', 'oracle', 'cisco', 'vmware', 'redhat',\n",
                "    \n",
                "    # === COMPANIES - OTHER ===\n",
                "    'ge', 'gm', 'ford', 'bmw', 'vw', 'kfc', 'mcdonalds',\n",
                "    'ups', 'fedex', 'dhl', 'usps', 'tnt',\n",
                "    'bp', 'shell', 'exxon', 'chevron', 'opec',\n",
                "    \n",
                "    # === MEDIA & ENTERTAINMENT ===\n",
                "    'tv', 'dvd', 'cd', 'hd', 'uhd', '4k', '8k', 'hdr', 'sdr',\n",
                "    'fm', 'am', 'dab', 'xm', 'sirius',\n",
                "    'espn', 'hbo', 'mtv', 'vh1', 'bet', 'amc', 'tnt', 'tbs',\n",
                "    'bbc', 'cnn', 'msnbc', 'fox', 'nbc', 'abc', 'cbs', 'pbs',\n",
                "    'npr', 'pbs', 'hgtv', 'tlc', 'bravo', 'e!',\n",
                "    'nfl', 'nba', 'mlb', 'nhl', 'mls', 'ufc', 'wwe', 'aew',\n",
                "    'fifa', 'uefa', 'ioc', 'ncaa', 'pga', 'lpga',\n",
                "    \n",
                "    # === EDUCATION & DEGREES ===\n",
                "    'phd', 'mba', 'md', 'jd', 'dds', 'dvm', 'pharmd',\n",
                "    'bs', 'ba', 'ms', 'ma', 'mfa', 'mph', 'msw',\n",
                "    'ged', 'sat', 'act', 'gre', 'gmat', 'lsat', 'mcat',\n",
                "    'ap', 'ib', 'stem', 'steam',\n",
                "    \n",
                "    # === UNIVERSITIES ===\n",
                "    'mit', 'ucla', 'usc', 'nyu', 'ucsb', 'ucsd', 'uci',\n",
                "    'ucf', 'usf', 'uf', 'fsu', 'lsu', 'osu', 'psu',\n",
                "    'byu', 'smu', 'tcu', 'uva', 'vcu', 'vmi', 'vt',\n",
                "    \n",
                "    # === BUSINESS & FINANCE ===\n",
                "    'ceo', 'cfo', 'cto', 'coo', 'cmo', 'cio', 'cso', 'cdo',\n",
                "    'vp', 'svp', 'evp', 'hr', 'pr', 'rd', 'qa', 'qc',\n",
                "    'llc', 'inc', 'ltd', 'corp', 'plc', 'gmbh', 'sa',\n",
                "    'ipo', 'roi', 'ebitda', 'kpi', 'roi', 'roa', 'roe',\n",
                "    'gdp', 'gnp', 'cpi', 'ppi', 'gdp', 'imf', 'wto',\n",
                "    'nyse', 'nasdaq', 'dow', 'sp', 'ftse', 'dax',\n",
                "    'etf', 'ira', '401k', 'roth', 'hsa', 'fsa',\n",
                "    'apr', 'apy', 'arm', 'fico', 'ach', 'eft', 'atm',\n",
                "    \n",
                "    # === AUTOMOTIVE ===\n",
                "    'suv', 'mpv', 'rv', 'atv', 'utv', '4wd', 'awd', 'fwd', 'rwd',\n",
                "    'mpg', 'mph', 'rpm', 'hp', 'bhp', 'psi', 'abs', 'esp',\n",
                "    'ac', 'dc', 'ev', 'phev', 'hev', 'ice', 'cvt', 'dct',\n",
                "    'vin', 'dmv', 'dui', 'dwi', 'drl', 'led', 'hid', 'oem',\n",
                "    \n",
                "    # === SCIENCE & MEASUREMENT ===\n",
                "    'nasa', 'esa', 'jaxa', 'isro', 'iss', 'ufo', 'uap',\n",
                "    'gps', 'gis', 'lidar', 'radar', 'sonar',\n",
                "    'uv', 'ir', 'rf', 'em', 'led', 'lcd', 'oled', 'qled',\n",
                "    'ac', 'dc', 'hz', 'khz', 'mhz', 'ghz', 'thz',\n",
                "    'kb', 'mb', 'gb', 'tb', 'pb', 'kbps', 'mbps', 'gbps',\n",
                "    \n",
                "    # === SOCIAL MEDIA & INTERNET ===\n",
                "    'seo', 'sem', 'ppc', 'cpc', 'cpm', 'ctr', 'roi',\n",
                "    'url', 'uri', 'www', 'tld', 'ccTLD', 'gtld',\n",
                "    'rss', 'xml', 'ajax', 'cors', 'jwt', 'oauth',\n",
                "    'dm', 'pm', 'im', 'sms', 'mms', 'rcs',\n",
                "    'gif', 'meme', 'nsfw', 'sfw', 'tldr', 'eli5',\n",
                "    \n",
                "    # === COMMON ABBREVIATIONS & SLANG ===\n",
                "    'asap', 'rsvp', 'fyi', 'btw', 'omg', 'lol', 'lmao', 'rofl',\n",
                "    'brb', 'afk', 'ttyl', 'gtg', 'idk', 'imo', 'imho',\n",
                "    'tbh', 'smh', 'fomo', 'yolo', 'bae', 'bff', 'ily',\n",
                "    'diy', 'faq', 'tba', 'tbd', 'eta', 'asap', 'rip',\n",
                "    'vip', 'mvp', 'goat', 'aka', 'fka', 'dba',\n",
                "    'etc', 'ie', 'eg', 'ps', 'pps', 'vs', 'aka',\n",
                "    'am', 'pm', 'bc', 'ad', 'bce', 'ce',\n",
                "    \n",
                "    # === ORGANIZATIONS ===\n",
                "    'un', 'nato', 'opec', 'asean', 'apec', 'brics',\n",
                "    'eu', 'nafta', 'usmca', 'wto', 'imf', 'who',\n",
                "    'unicef', 'unesco', 'interpol', 'icrc',\n",
                "    'ngo', 'npo', 'ong', 'ingo',\n",
                "    \n",
                "    # === LEGAL & LAW ===\n",
                "    'llc', 'inc', 'ltd', 'corp', 'pa', 'pc', 'lp', 'llp',\n",
                "    'dba', 'aka', 'fka', 'nka', 'poa', 'nda', 'tos',\n",
                "    'eula', 'gdpr', 'hipaa', 'ferpa', 'coppa', 'dmca',\n",
                "    \n",
                "    # === MISC ===\n",
                "    'pos', 'pin', 'ssn', 'ein', 'tin', 'vin', 'isbn', 'issn',\n",
                "    'upc', 'sku', 'ean', 'qr', 'rfid', 'nfc', 'ble',\n",
                "    'pda', 'gps', 'pos', 'atm', 'pos', 'eft', 'ach',\n",
                "    'hvac', 'led', 'lcd', 'crt', 'plasma', 'oled',\n",
                "    'jpeg', 'mpeg', 'ascii', 'utf', 'unicode',\n",
                "}\n",
                "\n",
                "print(f\"✓ Loaded {len(KNOWN_ACRONYMS)} known acronyms\")\n",
                "print(\"✓ Libraries ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Define Cleanup Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def should_remove_word(word):\n",
                "    \"\"\"\n",
                "    Check if a word should be removed.\n",
                "    \n",
                "    Removes:\n",
                "    - Words ending with apostrophe (word')\n",
                "    - 2-letter lowercase words (except 'a' and 'i')\n",
                "    \"\"\"\n",
                "    if pd.isna(word) or word == \"\":\n",
                "        return True\n",
                "    \n",
                "    word_str = str(word).strip()\n",
                "    \n",
                "    # Remove words ending with apostrophe\n",
                "    if word_str.endswith(\"'\"):\n",
                "        return True\n",
                "    \n",
                "    # Remove 2-letter lowercase words (except 'a' and 'i')\n",
                "    if len(word_str) == 2 and word_str.islower():\n",
                "        if word_str not in ['a', 'i']:\n",
                "            return True\n",
                "    \n",
                "    return False\n",
                "\n",
                "def fix_acronym(word):\n",
                "    \"\"\"\n",
                "    Fix acronyms that should be fully uppercase.\n",
                "    \n",
                "    Examples:\n",
                "    - Ny → NY\n",
                "    - Fbi → FBI\n",
                "    - Covid → COVID\n",
                "    - Nyc → NYC\n",
                "    - Usc → USC\n",
                "    \"\"\"\n",
                "    if pd.isna(word) or word == \"\":\n",
                "        return word\n",
                "    \n",
                "    word_str = str(word).strip()\n",
                "    word_lower = word_str.lower()\n",
                "    \n",
                "    # Check if it's a known acronym\n",
                "    if word_lower in KNOWN_ACRONYMS:\n",
                "        return word_str.upper()\n",
                "    \n",
                "    # Keep original capitalization\n",
                "    return word_str\n",
                "\n",
                "print(\"✓ Cleanup functions defined!\")\n",
                "print(\"\\nRules:\")\n",
                "print(\"  ✗ Words ending with ' (apostrophe)\")\n",
                "print(\"  ✗ 2-letter lowercase words (except 'a', 'i')\")\n",
                "print(f\"  ✓ Fix {len(KNOWN_ACRONYMS)} known acronyms to uppercase\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Load CSV File"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the CSV file\n",
                "print(\"Loading valid_words.csv...\")\n",
                "df = pd.read_csv('valid_words.csv')\n",
                "\n",
                "print(f\"✓ Loaded {len(df):,} words\")\n",
                "print(f\"\\nColumns: {list(df.columns)}\")\n",
                "print(f\"\\nFirst 10 rows:\")\n",
                "print(df.head(10))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Identify Words to Remove"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Analyzing words for removal...\\n\")\n",
                "\n",
                "# Mark words for removal\n",
                "df['should_remove'] = df['word'].apply(should_remove_word)\n",
                "\n",
                "# Separate into keep and remove\n",
                "to_remove = df[df['should_remove'] == True]\n",
                "to_keep = df[df['should_remove'] == False]\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"REMOVAL ANALYSIS\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"\\nTotal words: {len(df):,}\")\n",
                "print(f\"Words to keep: {len(to_keep):,}\")\n",
                "print(f\"Words to remove: {len(to_remove):,}\")\n",
                "\n",
                "# Show examples of words to remove\n",
                "if len(to_remove) > 0:\n",
                "    print(\"\\nExamples of words to remove:\")\n",
                "    \n",
                "    # Words ending with apostrophe\n",
                "    apostrophe_words = to_remove[to_remove['word'].str.endswith(\"'\", na=False)]\n",
                "    if len(apostrophe_words) > 0:\n",
                "        print(f\"\\n  Ending with ' ({len(apostrophe_words):,} words):\")\n",
                "        print(f\"    {apostrophe_words['word'].head(10).tolist()}\")\n",
                "    \n",
                "    # 2-letter lowercase words\n",
                "    two_letter = to_remove[to_remove['word'].apply(lambda x: len(str(x)) == 2 and str(x).islower())]\n",
                "    if len(two_letter) > 0:\n",
                "        print(f\"\\n  2-letter lowercase ({len(two_letter):,} words):\")\n",
                "        print(f\"    {two_letter['word'].head(20).tolist()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 7: Fix Acronyms"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nFixing acronyms...\\n\")\n",
                "\n",
                "# Apply acronym fixes to words we're keeping\n",
                "to_keep['fixed_word'] = to_keep['word'].apply(fix_acronym)\n",
                "\n",
                "# Find words that were changed\n",
                "changed = to_keep[to_keep['word'] != to_keep['fixed_word']]\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"ACRONYM FIXES\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"\\nWords changed: {len(changed):,}\")\n",
                "\n",
                "if len(changed) > 0:\n",
                "    print(\"\\nExamples of acronym fixes:\")\n",
                "    print(\"\\nOriginal → Fixed\")\n",
                "    print(\"-\" * 30)\n",
                "    for _, row in changed.head(30).iterrows():\n",
                "        print(f\"{row['word']:15s} → {row['fixed_word']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 8: Create Cleaned Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nCreating cleaned dataset...\\n\")\n",
                "\n",
                "# Create final dataframe with fixed words\n",
                "cleaned_df = to_keep[['fixed_word', 'count']].copy()\n",
                "cleaned_df = cleaned_df.rename(columns={'fixed_word': 'word'})\n",
                "\n",
                "# Deduplicate and merge counts\n",
                "print(\"Checking for duplicates after acronym fixes...\")\n",
                "before_dedup = len(cleaned_df)\n",
                "cleaned_df = cleaned_df.groupby('word', as_index=False).agg({'count': 'sum'})\n",
                "after_dedup = len(cleaned_df)\n",
                "\n",
                "print(f\"  Before deduplication: {before_dedup:,}\")\n",
                "print(f\"  After deduplication: {after_dedup:,}\")\n",
                "print(f\"  Duplicates merged: {before_dedup - after_dedup:,}\")\n",
                "\n",
                "# Sort by count descending\n",
                "cleaned_df = cleaned_df.sort_values('count', ascending=False)\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"FINAL STATISTICS\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"\\nOriginal words: {len(df):,}\")\n",
                "print(f\"Removed: {len(to_remove):,}\")\n",
                "print(f\"Final cleaned words: {len(cleaned_df):,}\")\n",
                "print(f\"\\nReduction: {len(df) - len(cleaned_df):,} words ({((len(df) - len(cleaned_df)) / len(df) * 100):.2f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 9: Preview Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"PREVIEW OF CLEANED WORDS\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "# Show top 20 words\n",
                "print(\"\\nTop 20 most frequent words:\")\n",
                "print(cleaned_df.head(20).to_string(index=False))\n",
                "\n",
                "# Show some acronyms if they exist\n",
                "acronyms_in_list = cleaned_df[cleaned_df['word'].str.isupper() & (cleaned_df['word'].str.len() <= 6)]\n",
                "if len(acronyms_in_list) > 0:\n",
                "    print(f\"\\nSample acronyms in list ({len(acronyms_in_list):,} total):\")\n",
                "    print(acronyms_in_list.head(30).to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 10: Save Cleaned Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save cleaned data\n",
                "print(\"\\nSaving cleaned data...\")\n",
                "\n",
                "cleaned_df.to_csv('cleaned_words.csv', index=False)\n",
                "print(f\"✓ Saved {len(cleaned_df):,} words to 'cleaned_words.csv'\")\n",
                "\n",
                "# Also save the removed words for review\n",
                "if len(to_remove) > 0:\n",
                "    to_remove[['word', 'count']].to_csv('removed_words.csv', index=False)\n",
                "    print(f\"✓ Saved {len(to_remove):,} removed words to 'removed_words.csv' (for review)\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"PROCESSING COMPLETE!\")\n",
                "print(\"=\" * 60)\n",
                "print(\"\\nDownload files from the Files panel:\")\n",
                "print(\"  - cleaned_words.csv (final cleaned list)\")\n",
                "print(\"  - removed_words.csv (removed words for review)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 11: (Optional) Detailed Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"DETAILED ANALYSIS\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "# Word length distribution\n",
                "cleaned_df['length'] = cleaned_df['word'].apply(len)\n",
                "print(\"\\nWord length distribution:\")\n",
                "print(cleaned_df['length'].value_counts().sort_index().head(15))\n",
                "\n",
                "# Capitalization breakdown\n",
                "print(\"\\nCapitalization breakdown:\")\n",
                "lowercase = len(cleaned_df[cleaned_df['word'].str.islower()])\n",
                "uppercase = len(cleaned_df[cleaned_df['word'].str.isupper()])\n",
                "capitalized = len(cleaned_df[cleaned_df['word'].str[0].str.isupper() & ~cleaned_df['word'].str.isupper()])\n",
                "\n",
                "print(f\"  Lowercase: {lowercase:,}\")\n",
                "print(f\"  UPPERCASE (acronyms): {uppercase:,}\")\n",
                "print(f\"  Capitalized: {capitalized:,}\")\n",
                "\n",
                "# Count statistics\n",
                "print(\"\\nCount statistics:\")\n",
                "print(f\"  Highest: {cleaned_df['count'].max():,}\")\n",
                "print(f\"  Lowest: {cleaned_df['count'].min():,}\")\n",
                "print(f\"  Average: {cleaned_df['count'].mean():.0f}\")\n",
                "print(f\"  Median: {cleaned_df['count'].median():.0f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "### Comprehensive Acronym Coverage (500+):\n",
                "\n",
                "This notebook includes **500+ acronyms** across categories:\n",
                "\n",
                "- **US States**: NY, CA, TX, FL, etc. (50)\n",
                "- **Health**: HIV, AIDS, COVID, DNA, RNA, SARS, etc.\n",
                "- **Technology**: API, CPU, GPU, RAM, HTML, CSS, SQL, etc.\n",
                "- **Companies**: IBM, HP, AMD, FBI, CIA, NASA, etc.\n",
                "- **Media**: ESPN, HBO, MTV, CNN, BBC, NFL, NBA, etc.\n",
                "- **Education**: PhD, MBA, MIT, UCLA, USC, NYU, etc.\n",
                "- **Business**: CEO, CFO, CTO, LLC, GDP, SEO, etc.\n",
                "- **Internet**: LOL, OMG, IDK, BTW, FYI, ASAP, etc.\n",
                "- **And many more...**\n",
                "\n",
                "### Example Transformations:\n",
                "\n",
                "```\n",
                "word'     → REMOVED\n",
                "ab        → REMOVED\n",
                "Ny        → NY\n",
                "Nyc       → NYC\n",
                "Usc       → USC\n",
                "Fbi       → FBI\n",
                "Covid     → COVID\n",
                "Hiv       → HIV\n",
                "Dna       → DNA\n",
                "Api       → API\n",
                "Seo       → SEO\n",
                "```"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}