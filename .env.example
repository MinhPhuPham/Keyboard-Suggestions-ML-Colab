# Environment Configuration Template
# Copy this file to .env and fill in your values
# DO NOT commit .env to git (it's in .gitignore)

# Hugging Face Token (optional, for private models or higher rate limits)
# Get token at: https://huggingface.co/settings/tokens
HF_TOKEN=your_huggingface_token_here

# Model Configuration
ENGLISH_MODEL_NAME=microsoft/Phi-3-mini-4k-instruct
JAPANESE_MODEL_NAME=Qwen/Qwen2-1.5B-Instruct

# Training Hyperparameters
BATCH_SIZE=32
LEARNING_RATE=1e-5
NUM_EPOCHS=3
MAX_SEQ_LENGTH=8

# LoRA Configuration
LORA_R=8
LORA_ALPHA=16
LORA_DROPOUT=0.1

# Optimization
PRUNING_AMOUNT=0.3
QUANTIZATION_BITS=8

# Paths (relative to project root)
DATA_DIR=./data
MODELS_DIR=./models
CHECKPOINTS_DIR=./checkpoints

# Target Model Specifications
ENGLISH_MODEL_SIZE_MB=30
JAPANESE_MODEL_SIZE_MB=60
TARGET_LATENCY_MS=50
